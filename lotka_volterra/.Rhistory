summed.data <- data.frame(time = c(1,2),
abu = colSums(all.data)[1:2]/sum(all.data[,1]))
lm(abu ~ time, data = summed.data)$coefficients[2]
summed.data
colSums(all.data)
all.data
# generating abundance data at four sites, in time 1 and time 2
all.data <- data.frame(time1=c(20, 2, 4 , 5),
time2=c(3,  4, 5,  10),
trend = NA)
#standardize each time series with abundance at time 1
std.data <- all.data
std.data[,1:2] <- all.data / all.data$time1
# trend at each site raw
for(i in 1:nrow(all.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(all.data[i,1:2]))
site.data
all.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
mean(all.data$trend)
# trend at each site - stdized
for(i in 1:nrow(std.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(std.data[i,1:2]))
site.data
std.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
# average trend at each site
mean(std.data$trend)
# trend of total abundance summed up across all sites
summed.data <- data.frame(time = c(1,2),
abu = colSums(all.data)[1:2]/sum(all.data[,1]))
lm(abu ~ time, data = summed.data)$coefficients[2]
# generating abundance data at four sites, in time 1 and time 2
all.data <- data.frame(time1=c(10, 2, 4 , 5),
time2=c(3,  4, 5,  10),
trend = NA)
#standardize each time series with abundance at time 1
std.data <- all.data
std.data[,1:2] <- all.data / all.data$time1
# trend at each site raw
for(i in 1:nrow(all.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(all.data[i,1:2]))
site.data
all.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
mean(all.data$trend)
# trend at each site - stdized
for(i in 1:nrow(std.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(std.data[i,1:2]))
site.data
std.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
# average trend at each site
mean(std.data$trend)
# trend of total abundance summed up across all sites
summed.data <- data.frame(time = c(1,2),
abu = colSums(all.data)[1:2]/sum(all.data[,1]))
lm(abu ~ time, data = summed.data)$coefficients[2]
# generating abundance data at four sites, in time 1 and time 2
all.data <- data.frame(time1=c(100, 2, 4 , 5),
time2=c(3,  4, 5,  10),
trend = NA)
#standardize each time series with abundance at time 1
std.data <- all.data
std.data[,1:2] <- all.data / all.data$time1
# trend at each site raw
for(i in 1:nrow(all.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(all.data[i,1:2]))
site.data
all.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
mean(all.data$trend)
# trend at each site - stdized
for(i in 1:nrow(std.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(std.data[i,1:2]))
site.data
std.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
# average trend at each site
mean(std.data$trend)
# trend of total abundance summed up across all sites
summed.data <- data.frame(time = c(1,2),
abu = colSums(all.data)[1:2]/sum(all.data[,1]))
lm(abu ~ time, data = summed.data)$coefficients[2]
# generating abundance data at four sites, in time 1 and time 2
all.data <- data.frame(time1=c(5, 2, 4 , 5),
time2=c(3,  4, 5,  10),
trend = NA)
#standardize each time series with abundance at time 1
std.data <- all.data
std.data[,1:2] <- all.data / all.data$time1
# trend at each site raw
for(i in 1:nrow(all.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(all.data[i,1:2]))
site.data
all.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
mean(all.data$trend)
# trend at each site - stdized
for(i in 1:nrow(std.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(std.data[i,1:2]))
site.data
std.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
# average trend at each site
mean(std.data$trend)
# trend of total abundance summed up across all sites
summed.data <- data.frame(time = c(1,2),
abu = colSums(all.data)[1:2]/sum(all.data[,1]))
lm(abu ~ time, data = summed.data)$coefficients[2]
# generating abundance data at four sites, in time 1 and time 2
all.data <- data.frame(time1=c(2, 2, 4 , 5),
time2=c(3,  4, 5,  10),
trend = NA)
#standardize each time series with abundance at time 1
std.data <- all.data
std.data[,1:2] <- all.data / all.data$time1
# trend at each site raw
for(i in 1:nrow(all.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(all.data[i,1:2]))
site.data
all.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
mean(all.data$trend)
# trend at each site - stdized
for(i in 1:nrow(std.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(std.data[i,1:2]))
site.data
std.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
# average trend at each site
mean(std.data$trend)
# trend of total abundance summed up across all sites
summed.data <- data.frame(time = c(1,2),
abu = colSums(all.data)[1:2]/sum(all.data[,1]))
lm(abu ~ time, data = summed.data)$coefficients[2]
# generating abundance data at four sites, in time 1 and time 2
all.data <- data.frame(time1=c(40, 2, 4 , 5),
time2=c(3,  4, 5,  10),
trend = NA)
#standardize each time series with abundance at time 1
std.data <- all.data
std.data[,1:2] <- all.data / all.data$time1
# trend at each site raw
for(i in 1:nrow(all.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(all.data[i,1:2]))
site.data
all.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
mean(all.data$trend)
# trend at each site - stdized
for(i in 1:nrow(std.data))
{
site.data <- data.frame(time = c(1,2),
abu = unlist(std.data[i,1:2]))
site.data
std.data$trend[i] <- lm(abu ~ time, data =  site.data)$coefficients[2]
}
# average trend at each site
mean(std.data$trend)
# trend of total abundance summed up across all sites
summed.data <- data.frame(time = c(1,2),
abu = colSums(all.data)[1:2]/sum(all.data[,1]))
lm(abu ~ time, data = summed.data)$coefficients[2]
# generating abundance data at four sites, in time 1 and time 2
all.data <- data.frame(time1=c(20, 2, 4 , 5),
time2=c(3,  4, 5,  10),
trend = NA)
mu <- 0.5
sd <- 0.1
rnorm(1, mu, sd)
mu1 <- 0.5
sd1 <- 0.1
sp1 <- rnorm(1, mu1, sd1)
sp1
sp1 <- rnorm(100, mu1, sd1)
sp1
sp2 <- rnorm(100, mu2, sd2)
mu1 <- 0.5
sd1 <- 0.1
sp1 <- rnorm(1000, mu1, sd1)
mu2 <- 0.2
sd2 <- 0.1
sp2 <- rnorm(1000, mu2, sd2)
hist(sp1)
sp2 <- rnorm(1000, mu2, sd2)
hist(sp2)
sp1 + sp2
hist(sp1 + sp2)
mu1 <- 0.9
sd1 <- 0.1
sp1 <- rnorm(1000, mu1, sd1)
hist(sp1)
mu2 <- 0.8
sd2 <- 0.1
sp2 <- rnorm(1000, mu2, sd2)
hist(sp2)
hist(sp1 + sp2)
hist(rbeta(n = 10000, shape1= 1, shape2=1))
hist(rbeta(n = 10000, shape1= 10, shape2=1))
hist(rbeta(n = 10000, shape1= 1, shape2=10))
hist(rbeta(n = 10000, shape1= 10, shape2=10))
hist(rbeta(n = 10000, shape1= 0.10, shape2=0.10))
hist(rbeta(n = 10000, shape1= 10, shape2=10))
hist(rbeta(n = 10000, shape1= 50, shape2=50))
hist(rbeta(n = 10000, shape1= 150, shape2=150))
rbeta(n = 1000, shape1= 10, shape2=2)
hist(rbeta(n = 1000, shape1= 10, shape2=2))
sp1 <- rbeta(n = 1000, shape1= 10, shape2=2)
sp2 <- rbeta(n = 1000, shape1= 2, shape2=10)
sp1
hist(sp2)
sum(sp1, sp2)
sp1+sp2
hist(sp1+sp2)
mean(sp1+sp2)
sd(sp1+sp2)
library(randomForest)
?importance
params <- expand.grid(S = c(10, 100),
M = c(10, 100),
Amu = c(-0.9, -0.5, -0.1),
d_z = seq(1, 3, by = 0.2))
# repeat each combination of parameters rep.times
rep.times <- 10
params <- do.call("rbind", replicate(rep.times, params, simplify = FALSE))
# set times at which the community will be sampled
time1 = 10
time2 = 20
nrow(params)
library(devtools)
require(deSolve)
install.packages("deSolve")
require(deSolve)
require(viridis)
require(tidyverse)
require(gridExtra)
require(randomForest)
require(ggplot2)
system("R CMD SHLIB LVmod_metacom_log.c") # compile C code (needs Rtools)
source("LV_misc_functions.R")
setwd("C:/Users/Keil/Dropbox/GitHub/extinction_scaling_simulations/lotka_volterra")
system("R CMD SHLIB LVmod_metacom_log.c") # compile C code (needs Rtools)
source("LV_misc_functions.R")
params <- expand.grid(S = c(10, 100),
M = c(10, 100),
Amu = c(-0.9, -0.5, -0.1),
d_z = seq(1, 3, by = 0.2))
# repeat each combination of parameters rep.times
rep.times <- 10
params <- do.call("rbind", replicate(rep.times, params, simplify = FALSE))
# set times at which the community will be sampled
time1 = 10
time2 = 20
set.seed(12345)
#initialize results container
results <- list()
# the loop
for(i in 1:nrow(params))
# the loop
for(i in 1:nrow(params))
{
print(paste("Simulation",i, "out of", nrow(params)))
n0mu = 0.01 # mean starting abundance
n0sd = n0mu/2 # sd starting abundance
Kmu = 1 # mean K
Ksd = 0 # sd K
rmu = 1 # mean r
rsd = 0 # sd r
#Amu = -0.5 # mean interaction strength
Amu = params$Amu[i]
Asd = 0.2 # sd interaction strength
cmu = 0 # mean dispersal rate
csd = 0.2 # sd dispersal rate (among species)
minval = -999 # log(minval) is lower limit below which abundances are no longer tracked
# note - species only "die" in a cell if their abundance is driven to zero, but the -999 limit lets us avoid
# using lots of computational power to track infintesimally small abundances
M = params$M[i]  # number of sites
N0 = params$S[i] # number of species (in global pool)
D = N0 # dimensionality of interaction matrix
steps = 20 # number of simulation steps
# make interaction matrix
Amat = matrix(nrow = N0, ncol = N0)
Amat[row(Amat)!=col(Amat)] = rnorm(N0^2-N0, Amu, Asd)
diag(Amat) = -1
# store prameters in a vector
Pars  <- c(N   = N0,                         # number of species
M   = M,                          # number of patches
minval = minval,                  # minimum population size to track
K   = pmax(0, rnorm(N0, Kmu, Ksd)),   # vector of carrying capacities
r  = rnorm(N0, rmu, rsd),         # vector of initial growth rates
A  = c(Amat),                     # interaction coefficients
d_c = 0.5,                          # proc. noise c
d_z = params$d_z[i],                          # proc. noise z
d_n = 0,                          # proc. noise nugget
d_m = 0,                          # proc. noise mean
d_w = 1,                          # disturbance waiting time
cv  = pmax(0, rnorm(N0, cmu, csd)),   # dispersal rate
n0 = abs(rep(n0mu, N0)))          # initial abundance post-colonization
# process noise follows the formula:
#dsd = sqrt(dc*n^dz);
#n_new = n + (dsd+dn)*rnorm(1)+dm;
# make initial abundances
nini  <- abs(rnorm(N0*M, n0mu, n0sd))
nini  <- rlnorm(n = N0*M, meanlog = 1, sdlog = 1)
# time to record abundances in simulation
times <- seq(0, steps, by = 1)
# log transform initial states - allows for more stable simulations
lnini = log(nini)
lnini[!is.finite(lnini)] = minval
# dummy variable for tracking disturbance times
lnini = c(lnini, 1, runif(1))
# dummy variable for tracking dispersal effects
lnini = c(lnini, rep(1, N0), runif(N0, 0.5, 1))
dyn.load("LVmod_metacom_log.so") # load c code
# run C code
out_C <- ode(y = lnini,
times = times,
func = "derivs",
parms = Pars,
dllname = "LVmod_metacom_log",
initfunc = "initmod",
events = list(func = "event", root = TRUE),
rootfun = "myroot",
nout = N0,
nroot = N0+1)
dyn.unload("LVmod_metacom_log.so") # unload c code (helps with stablity)
# output: array with 3 dimensions (time, species, sites)
Mout = array(dim =c(nrow(out_C), N0, M))
Mout[] = exp(out_C[,1:(N0*M)+1])
Mout.gamma <- apply(Mout, 1:2, sum)
# ------------------------------------
# extract Px and Ex using time1 and time2
MAT <- Mout.gamma
EXTract(MAT, time1, time2)
PXTract(MAT, time1, time2)
# number of extinctions at gamma scale
E.gamma <- EXTract(Mout.gamma,
time1,
time2)
# per-species prob of extinction at gamma scale
P.gamma <- PXTract(Mout.gamma,
time1,
time2)
# mean number of extinctions at alpha scale
E.alpha <- mean(apply(X = Mout,
FUN = EXTract,
MARGIN = 3,
time1,
time2))
# per-species prob of extinction
P.alpha <- mean(apply(X = Mout,
FUN = PXTract,
MARGIN = 3,
time1,
time2))
# slopes of PxAR and ExAR (note: slope = rise/run)
P.slope <- (P.gamma-P.alpha) / (time2-time1)
E.slope <- (E.gamma-E.alpha) / (time2-time1)
results[[i]] <- c(params[i,],
P.alpha = P.alpha,
P.gamma = P.gamma,
P.slope = P.slope,
E.slope = E.slope)
} # end of the main loop
rm(list=ls())
require(deSolve)
require(viridis)
system("R CMD SHLIB LVmod_metacom_log.c") # compile C code (needs Rtools)
source("LV_misc_functions.R")
#-------------------------------------------------------------------------------
n0mu = 0.01 # mean starting abundance
n0sd = n0mu/2 # sd starting abundance
Kmu = 1 # mean K
Ksd = 0 # sd K
rmu = 1 # mean r
rsd = 0 # sd r
Amu = -0.8 # mean interaction strength
Asd = 0.2 # sd interaction strength
cmu = 0 # mean dispersal rate
csd = 0.2 # sd dispersal rate (among species)
minval = -999 # log(minval) is lower limit below which abundances are no longer tracked
# note - species only "die" in a cell if their abundance is driven to zero, but the -999 limit lets us avoid
# using lots of computational power to track infintesimally small abundances
M = 5 # number of sites
N0 = 12 # number of species (in global pool)
D = N0 # dimensionality of interaction matrix
steps = 20 # number of simulation steps
# make interaction matrix
Amat = matrix(nrow = N0, ncol = N0)
Amat[row(Amat)!=col(Amat)] = rnorm(N0^2-N0, Amu, Asd)
diag(Amat) = -1
# store prameters in a vector
Pars  <- c(N   = N0,                         # number of species
M   = M,                          # number of patches
minval = minval,                  # minimum population size to track
K   = pmax(0, rnorm(N0, Kmu, Ksd)),   # vector of carrying capacities
r  = rnorm(N0, rmu, rsd),         # vector of initial growth rates
A  = c(Amat),                     # interaction coefficients
d_c = 0.5,                          # proc. noise c
d_z = 1,                          # proc. noise z
# >2 means that more abundant species are hit more than less abund.
d_n = 0,                          # proc. noise nugget
d_m = 0,                          # proc. noise mean
d_w = 1,                          # disturbance waiting time
cv  = pmax(0, rnorm(N0, cmu, csd)),   # dispersal rate
n0 = abs(rep(n0mu, N0)))          # initial abundance post-colonization
# process noise follows the formula:
#dsd = sqrt(dc*n^dz);
#n_new = n + (dsd+dn)*rnorm(1)+dm;
# make initial abundances
nini  <- abs(rnorm(N0*M, n0mu, n0sd))
# time to record abundances in simulation
times <- seq(0, steps, by = 1)
# log transform initial states - allows for more stable simulations
lnini = log(nini)
lnini[!is.finite(lnini)] = minval
# dummy variable for tracking disturbance times
lnini = c(lnini, 1, runif(1))
# dummy variable for tracking dispersal effects
lnini = c(lnini, rep(1, N0), runif(N0, 0.5, 1))
dyn.load("LVmod_metacom_log.so") # load c code
# run C code
out_C <- ode(y = lnini,
times = times,
func = "derivs",
parms = Pars,
dllname = "LVmod_metacom_log",
initfunc = "initmod",
events = list(func = "event", root = TRUE),
rootfun = "myroot",
nout = N0,
nroot = N0+1)
dyn.unload("LVmod_metacom_log.so") # unload c code (helps with stablity)
# output: array with 3 dimensions (time, species, sites)
Mout = array(dim =c(nrow(out_C), N0, M))
Mout[] = exp(out_C[,1:(N0*M)+1])
Mout.gamma <- apply(Mout, 1:2, sum)
# -----------------------------------
time1 = 5
time2 = 12
MAT <- Mout.gamma
EXTract(MAT, time1, time2)
PXTract(MAT, time1, time2)
# number of extinctions at gamma scale
P.ext.gamma <- PXTract(Mout.gamma,
time1,
time2)
P.ext.gamma
# mean number of extinctions at alpha scale
P.ext.alpha <- mean(apply(X = Mout,
FUN = PXTract,
MARGIN = 3,
time1,
time2))
P.ext.alpha
# plot total biomass of each species at the metacommunity scale
matplot(Mout.gamma, type = "l")
abline(h=0)
abline(v = time1); abline(v=time2)
# plot mean output at gamma scale
par(mfrow=c(2,2), mar=c(4,4,2,2))
matplot(times, apply(Mout, 1:2, mean), lty = 1, type = "l", lwd = 2,
xlab = "time", ylab = "Species Abundance n, Gamma", col = viridis(N0))
abline(h=0, lty=3)
#  plot alpha-level dynaimcs for each site
par(mfrow=c(2,2), mar=c(4,4,2,2))
for(i in 1:M) {
matplot(times, Mout[,,i], lty = 1, type = "l", lwd = 2,
xlab = "time", ylab = "n, alpha", col = viridis(N0))
abline(h=0, lty=3)
}
Pout = out_C[,ncol(out_C)+1-(N0:1)]
par(mfrow=c(2,2), mar=c(4,4,2,2))
matplot(times, Pout, lty = 1, type = "l", lwd = 2,
xlab = "time", ylab = "p", col = viridis(N0))
abline(h=0, lty=3)
par(mfrow=c(2,2), mar=c(4,4,2,2))
matplot(times, apply(Mout, 1:2, mean), lty = 1, type = "l", lwd = 2,
xlab = "time", ylab = "Species Abundance n, Gamma", col = viridis(N0))
abline(h=0, lty=3)
# plot total biomass of each species at the metacommunity scale
matplot(Mout.gamma, type = "l")
abline(h=0)
abline(v = time1); abline(v=time2)
params <- expand.grid(S = c(10, 100),
M = c(10, 100),
Amu = c(-0.9, -0.5, -0.1),
d_z = seq(1, 3, by = 0.2))
nrow(params)
